{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage C Quiz Answers By Joe Iroegbu ID: 413452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data_for_UCI_named.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   tau1    10000 non-null  float64\n",
      " 1   tau2    10000 non-null  float64\n",
      " 2   tau3    10000 non-null  float64\n",
      " 3   tau4    10000 non-null  float64\n",
      " 4   p1      10000 non-null  float64\n",
      " 5   p2      10000 non-null  float64\n",
      " 6   p3      10000 non-null  float64\n",
      " 7   p4      10000 non-null  float64\n",
      " 8   g1      10000 non-null  float64\n",
      " 9   g2      10000 non-null  float64\n",
      " 10  g3      10000 non-null  float64\n",
      " 11  g4      10000 non-null  float64\n",
      " 12  stab    10000 non-null  float64\n",
      " 13  stabf   10000 non-null  object \n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     float64\n",
       "tau2     float64\n",
       "tau3     float64\n",
       "tau4     float64\n",
       "p1       float64\n",
       "p2       float64\n",
       "p3       float64\n",
       "p4       float64\n",
       "g1       float64\n",
       "g2       float64\n",
       "g3       float64\n",
       "g4       float64\n",
       "stab     float64\n",
       "stabf     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250001</td>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249997</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.015731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.742548</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742556</td>\n",
       "      <td>0.752160</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.500141</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.500473</td>\n",
       "      <td>1.582590</td>\n",
       "      <td>-1.999891</td>\n",
       "      <td>-1.999945</td>\n",
       "      <td>-1.999926</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050053</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.080760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.874892</td>\n",
       "      <td>2.875140</td>\n",
       "      <td>2.875522</td>\n",
       "      <td>2.874950</td>\n",
       "      <td>3.218300</td>\n",
       "      <td>-1.624901</td>\n",
       "      <td>-1.625025</td>\n",
       "      <td>-1.624960</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>0.287552</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.287494</td>\n",
       "      <td>-0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249981</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>5.249734</td>\n",
       "      <td>3.751025</td>\n",
       "      <td>-1.249966</td>\n",
       "      <td>-1.249974</td>\n",
       "      <td>-1.250007</td>\n",
       "      <td>0.525009</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.525002</td>\n",
       "      <td>0.017142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.624690</td>\n",
       "      <td>7.624893</td>\n",
       "      <td>7.624948</td>\n",
       "      <td>7.624838</td>\n",
       "      <td>4.282420</td>\n",
       "      <td>-0.874977</td>\n",
       "      <td>-0.875043</td>\n",
       "      <td>-0.875065</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>0.762490</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.762433</td>\n",
       "      <td>0.044878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999469</td>\n",
       "      <td>9.999837</td>\n",
       "      <td>9.999450</td>\n",
       "      <td>9.999443</td>\n",
       "      <td>5.864418</td>\n",
       "      <td>-0.500108</td>\n",
       "      <td>-0.500072</td>\n",
       "      <td>-0.500025</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.109403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tau1          tau2          tau3          tau4            p1  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       5.250000      5.250001      5.250004      5.249997      3.750000   \n",
       "std        2.742548      2.742549      2.742549      2.742556      0.752160   \n",
       "min        0.500793      0.500141      0.500788      0.500473      1.582590   \n",
       "25%        2.874892      2.875140      2.875522      2.874950      3.218300   \n",
       "50%        5.250004      5.249981      5.249979      5.249734      3.751025   \n",
       "75%        7.624690      7.624893      7.624948      7.624838      4.282420   \n",
       "max        9.999469      9.999837      9.999450      9.999443      5.864418   \n",
       "\n",
       "                 p2            p3            p4            g1            g2  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -1.250000     -1.250000     -1.250000      0.525000      0.525000   \n",
       "std        0.433035      0.433035      0.433035      0.274256      0.274255   \n",
       "min       -1.999891     -1.999945     -1.999926      0.050009      0.050053   \n",
       "25%       -1.624901     -1.625025     -1.624960      0.287521      0.287552   \n",
       "50%       -1.249966     -1.249974     -1.250007      0.525009      0.525003   \n",
       "75%       -0.874977     -0.875043     -0.875065      0.762435      0.762490   \n",
       "max       -0.500108     -0.500072     -0.500025      0.999937      0.999944   \n",
       "\n",
       "                 g3            g4          stab  \n",
       "count  10000.000000  10000.000000  10000.000000  \n",
       "mean       0.525000      0.525000      0.015731  \n",
       "std        0.274255      0.274255      0.036919  \n",
       "min        0.050054      0.050028     -0.080760  \n",
       "25%        0.287514      0.287494     -0.015557  \n",
       "50%        0.525015      0.525002      0.017142  \n",
       "75%        0.762440      0.762433      0.044878  \n",
       "max        0.999982      0.999930      0.109403  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stabf\n",
      "stable      3620\n",
      "unstable    6380\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('stabf').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAD/CAYAAADCOHwpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVg0lEQVR4nO3dfZBldX3n8feXQWDo0UGqsVEi0yoJajKEOJNIbUVsAzEoutRaeagEXTVaQ6q0TCpTuxLXh3WTJSS7aCrqLjXZNViI8SG7iRokD1amRbcWNjPGOOUDFdEBHRxwYBhmWmbGGb/7xzlNLk0/3O4+95zfvf1+Vd2i+/a5537vZy6fPn3OvedGZiJJKscpXQ8gSXo8i1mSCmMxS1JhLGZJKozFLEmFsZglqTAWsyQVZqSKOSJOi4g/j4i9EZERMdX1TKMmIi6JiL+LiIci4nsR8YmIeHrXc42SiHh+ROyKiIP15bMR8fyu5xpFEfGuuisu73qWXiNVzLUvAK8G9nc9yIh6KrADmAQ2AYeBP+1yoBF0H/CLwNnAOPAp4KOdTjSCIuI5VDl/t+tZ5jq16wFWIiJeAPxP4ALgr4EfAv+cmW8H/qhe5mR3Ew6/JTLuXe79wOfan3D4LZHxw/UyAZysl9Ey9PEcfj/wVuC/dTPhwoZuizkiTgP+AriJaoviz4B/0+VMo2aZGV8KfKWdyUZHPxlHxMPAUeB9wHUtjzjUlso3In4JOJ6Zn+lkwCUM4xbzJVRz/3FWJ/r43xHx/zqeadT0lXFEXAS8E7iq5flGwZIZZ+ZZETEGvBa4p4MZh9mC+UbEBqpfdC/tcL5FDWMxPwPYl48/+9K3uxpmRC2ZcURcANwG/GZmfr7N4UZEX8/jzJyJiBuB70XE8zLzgdYmHG6L5ftu4ObM/Fb7Y/Vn6HZlUO2oP6/e9zbrmV0NM6IWzTgiNgGfBX43M29ue7gRsZzn8SnAmcB5A59qdCyW72XAWyJif0Tsr6//eES8te0hFzKMxfx/qQ6GvDkiTo2Iq4Cfmf1hRJweEWfU354WEWfM+cfR0hbMOCLOA/4e+EBm3tjhjMNusYx/PiJ+KiLWRcRTgPcAB4GvdTfu0FmsJy4DfgK4uL7cB1wDfKCLQeczdMWcmceBVwFvoDpy/Wrgr4Bj9SJ3AY9SbV38Tf31pvYnHV5LZPxG4NnAuyLiyOyls2GH1BIZn0V1sOoQcDfVqwquyMyj3Uw7fBbLNzMfzMz9sxeqAj+YmcU8j2MUTpQfEXcCN2amr6cdEDMePDMerGHKd+i2mAEi4sURcW79J8prgYuoXqeohpjx4JnxYA1zvsP4qgyAC4GPAxuo/tT7xcws7t07Q86MB8+MB2to8x2JXRmSNEqGcleGJI2yRnZljI+P5+TkZBOrWpGZmRnGxsY6u/+5M+zevftAZp7T5PrNeLAZd50vmHEbus6473wzc9WXLVu2ZJd27tzZ6f3PnQHYlQ3kmma84AxNZ9x1vplm3IauM+4332E9+NeZyWtvnff6m67odkunVAvltff6K1uepH8LzQzLn3sYH38bRj2X1fbEogf/IuJSqhdk3znPz7YB2wAmJia2fPSj1eli9+w71NcdN2liPdz/aOt3+zjP2riODRs2APCSl7xkd2Zu7ed2Zty/pjMuKV8w4zZ0nXG/+TbyqoytW7fmrl27gMW3NgZl++YT3LCn243/m64YY2pqCoCI6PsJ3S8zHmzGXecLZtyGrjPuN19flSFJhbGYJakwFrMkFcZilqTCWMySVBiLWZIKYzFLUmEsZkkqjMUsSYWxmCWpMBazJBXGYpakwljMklQYi1mSCmMxS1JhLGZJKozFLEmFsZglqTAWsyQVxmKWpMJYzJJUGItZkgpjMUtSYSxmSSqMxSxJhbGYJakwFrMkFcZilqTCWMySVBiLWZIKYzFLUmEsZkkqjMUsSYWxmCWpMBazJBXGYpakwljMklQYi1mSCmMxS1JhTu16gKbkyR9w4FP/hWP7v8HJRx5g4lev44zzL+p6rJFybN/XefjzH+b4/d+AOIUzzt/MUy+/hlM3nN31aCPj+IF7efDW93Di4HcBOO3cC3jq5ddw2vj5HU82mh7+wkc49H8+wtN+5fdYP3lx1+M8JjJz6YUiLsnMO+Zctw3YVn97IXBX8+P1bRx4EDgH+D7wbOBbwOGWZzhQf70pM89Zzo2HJOPjwDrgUH3d+cCTgH9ucYbGMi4sX6ge30GqjI/X1z2tvv6rLc4w6hnPPr7TgedQbaC21Rf95ZuZQ3UB9gK/Q/VEPQj8KbB7zjLfAaZanmtX19m0mXG93AuAw2Y8mIypCuNNwPfNuPmMgduAl9fLXV5SvsO6K+Nq4BeAGeDTwNO7HWck9ZPxpcBX2hxqxCyYcUQ8DGygOg70zk6mGw3zZhwRvwQcz8zPRESH481vWA/+vT8zv52ZDwH/GXAnZ/MWzTgiLqIqjH/XxXAjYsGMM/MsYCPwZuAfO5pvFDwh44jYAFwH/Fa3oy1sWLeYv93z9T2U8QtmR9cDNGzBjCPiAqo/A38zMz/f4kxrJmOAzJyJiBuB70XE8zLzgRZmWgsZvxu4OTO/1cE8feVbQqGtxDN7vj6fx4fficwctSf0vBlHxCbgs8DvZubNbQ60VjKe4xTgTOC8NgZaIxlfBrwlIvZHxP56mY9HxFsHPUy/+Q5rMb8pIn4kIs4G3gZ8DCAiTo+IM+plTouIM6LEHUjD4QkZR8R5wN8DH8jMG7sdbyTMl/HPR8RPRcS6iHgK8B6qA1df63TS4TVfV1wG/ARwcX25D7gG+EBnU84xrMX8EeBvgW/Wl9+rr78LeJRq6+Jv6q83dTHgCJgv4zdSvRTxXRFxZPbS4YzDbr6MzwL+jOoliXcDFwBXZObRroYcck/IODMfzMz9sxfgJHAwM4t5Lg9rMf9DZj6/PkDywcz8PkBmTmZmzLnsHfQwEXHpoO+jA0/IODPfXWe6offSxjBrKONPZOZz62zPycyXZ+aX2xhmrWQ8d4G6Nz7bxjD9ZjysxfyYzPxcATPc3vUMg2TGg2fGgzdMGQ99MUvSqOnrLdmSpPa4xSxJhWnkDSbj4+M5OTm54tvPzMwwNjbWxCiNWO08u3fvPpDLPPnLUnozLi2v+Qx6xqYzHrZ8wYzbMMg5F823iRNzbNmyJVdj586dq7p901Y7DwM4EUxvxqXlNZ9Bz9h0xsOWb6YZt2GQcy6W71C+JXvy2luXtfze668c0CSD1XvKxImJCaanpwF44KFDvO+WT3Y42dIm1tP4jJvP29jo+oY5XzDjNjSdcb/5DmUxj5L6dY3HMvPOuT/L6u2bOwC2bt2aU1NTQPVEuWFP2f902zefaHzGvVdPreh2C2U8zPmCGbeh6Yz7zXfRe4yIFwNH5yuNhX4TrsSRI0eWdfvtm08sa/3LnW2586xGjvhrR0tgxoNnxs1atJhzkRdkL/SbcCWmp6dZzu1ft9xdGcvcCljuPJLUJF8uJ0mFsZglqTAWsyQVxmKWpMJYzJJUGItZkgpT/iu8G7DQOwWH9R2BkkZbscW83LddS9KocFeGJBXGYpakwljMklQYi1mSCmMxS1JhLGZJKozFLEmFsZglqTAWsyQVxmKWpMIU+5bsNiz0tu+brhhreRJJ+hduMUtSYSxmSSpM57syJq+9le2bTyz7k68laVS5xSxJhbGYJakwFrMkFcZilqTCWMySVBiLWZIKYzFLUmEsZkkqjMUsSYVp7Z1/C50wqER79h1a8J2Ie6+/suVpJK01bjFLUmEsZkkqjMUsSYWxmCWpMJ2f9nPYLHQQ04OCkprSeDGX9uqLo/d+mQOfvoEfedOHuh5FkvoSmbmyG0ZsA7bV314I3LWKOcaBA30u+wzgdOBbfS7/ZOBZwJcHNM98NmXmOau4PbBoxqudb9ZmYC9wuIF1PQM4C1gPfBc4TjMzLmTVGbeQLzSX8anAM6mez6cAR4FHgPtWud7FrLWMAX6M6jl8CnCsXue3G1jvfBbONzOXvACX9LPcSi/ArmUs+x+BDy9j+SngO4Oap8EM+s64qfmonsyXN7Su1wIvAz5Z/xu1nmFTGTc5e1MZA88Gfht4OrCOqux+AGzoOtdRybhe10XAqfXXLwROAk9vO8e+Dv5l5h39LNe0iHhrROyLiMMRcVdEXAm8DfiViDgSEf9UL/f6iPhavdw3I+Kaedb1tog4EBF7I+Lqth/LUtrOOCJuBs4HPl1n+e8j4hMRsT8iDkXE7RHx4z3LT0fEG3u+f11EfKFn/g9l5m00s9UyEMOccWZ+MzPfk5nfzcyTmbmDaqvuwjYf01KGOeN6/i9n5onZb4Gg+kulVcW+KiMiLgTeDPx0Zj4Z+AXg68B1wMcyc0Nm/mS9+APAK4CnAK8H3hsRL+hZ3blUfzqdR7Vlt6Ne/5qVma8B7gVeWWf5h8BtwI8CTwO+CNzS4YhDb5AZR8TFVKXxjYbGHUqDyDgi/ioijgJ3Um1o7Gp26qWVUsw75rnuJNW+5OdHxJMyc29m3j3fjTPz1sy8OyufA/4WeNGcxd6Rmcfqn98K/PIy5ynJQObLzA9m5uHMPEa1O+InI2LjCldXeoaLGdjsTWQcEU8Bbgb+MjMPDWDMNhSbcWa+gmpf/suBv87MHw5m0oUVUcz1n2Vzr/sG8FtUwT4QER+NiGfMd/uIeFlE3BERD0XEw1SBjvcscjAzZ3q+v4fqYFXf85RkEPNFxLqIuD4i7o6IR6j228Hjc+xb6RkuZlCzN5FxRKwHPg3ckZmvGsCYrSg5Y4DM/EG9a25jRPzrpudcShHFvJDM/Ehm/iywiWp/zx/U/31MRJwO/C/gvwITmXkW8BmqP/NmPTUixnq+P5/BHs0eFr1Z/hpwFXA5sBGYrK+fzXEGOLNn+XMHPdyIaCzj+rn+l8A+4AnHUdawQT6PTwWes/oRl6fYYo6ICyPi5+on41HgUardG/cDkxExO/tpVLs8vgeciIiXAS+dZ5XvjojTIuJFVPujPzHwB1G++6mO9kP1p9sx4EGqJ+51c5b9EvCqiDgzIi4A3tD7w4h4UkScQfWcOjUizoiIdQOdfjg0knFEPAn4c6r/D/5tF39eF6ypjJ9b//W9vn4+vxq4FPjcwB/BHJ0Xc0S8cIEfnQ5cT/Vax/1UO/Lfxr8U6oMR8cXMPAy8Bfg4cJDqN+an5qxrf/2z+6gOBPxGZn59kZlevLJHM3gRcWVEbG5odb8PvL3e/XM21S6efcBXgblH199L9drk+4EP8cQDKn9CVRq/CvyH+uvXNDRnqwrN+F9RbVC8FHg4Ih6NiJl6Q2PoFJpxUO86pdrQeyfw25n5xYbm7NuK32AiSRqMzreYJUmPZzFLUmEsZkkqjMUsSYVp5LSf4+PjOTk52cSq+jYzM8PY2NjSC3Yww+7duw9kA2eX69VFxr1Ky7vpjLvOF8y4DV1n3He+TZwJacuWLdm2nTt3tn6f/c7AAM6s1kXGvUrLu+mMu84304zb0HXG/eY7Up9gMoyfLhIRlwLHMvPOeX722LlsJyYmmJ6eBmDPvvZPjzCxHt53yydbv99ez9q47rEMlmOhjEvKF8y4DV1n3G++I1XMwygzb1/kZzuoT/aydevWnJqaAuB1HXxKzPbNJ7hhT7dPl5uuGGM2g+VYKOOS8gUzbkPXGfebrwf/JKkwa2KLeRh3cUhau9xilqTCWMySVJhid2UstPsB3AUhabQVW8yLmbz2VrZvPtHZkV1JGiR3ZUhSYSxmSSpM57syFtuXLElrkVvMklQYi1mSCtP5rowu+Y5ASSVyi1mSCmMxS1JhLGZJKozFLEmFWfTg30o+XWO5tm8+saLbTaxf+W2X0u9jOXLkyIoftyQtZNFiXsmnayzXSs93MchPIth79VRfy01PT6/o0x4kaTHuypCkwljMklQYi1mSCmMxS1JhLGZJKozFLEmFsZglqTAWsyQVxmKWpMKs6fMxL2Sxj7vyXM2SBs0tZkkqTGtbzH7oqiT1xy1mSSqMxSxJhbGYJakwFrMkFcZilqTCWMySVBiLWZIKYzFLUmF8S/Yy9b5RZvvmE499mKxv1ZbUlKK3mL/z33+dR/d+qdF1Hr13D/f8wSs4ePvNja5XkpoSmbn0QhGXZOYdc67bBmyrv70QuKv58dgM7AUOz/OzceDAMtcXwPOAHwKPAPetZrhFZtiUmecsa7DuMu7XSvIe5AyrzriwfMGM29B1xn3l21cxdyEibgauBo4BJ4H/BPw08CJgPdXW/iWZ+ZV6+Wngw5n5P+rvXwe8MTN/tmed1wJnA08DvpOZb1/ljLsyc+tq1jEsSnisJcwwSCU8vhJmGKSuH1+/91/srozMfA1wL/DKzNyQmX8I3Ab8KFWxfh+4pd/1RcQm4NepCl6SijVUB/8y84OzX0fEfcDFEbExMw/1cfM/Bt6RmUciYmAzStJqFbvFPFdErIuI6yPi7oh4hGp/FVT7bJa67SuBJ2fmxxoea0fD6ytZCY+1hBkGqYTHV8IMg9T14+vr/kvfYu7dAf5rwFXA5VQHBDcCB6kO6AHMAGf2LH9uz9eXAVsjYn/9/UbgZERszsyrVjxcZtf/yK0p4bGWMMMglfD4SphhkLp+fP3ef+lbzPcDz66/fjLVgcAHqQr4ujnLfgl4VUScGREXAG/o+dk7gB8DLq4vnwL+BHj94EaXpJUpvZh/H3h7RDxM9WqKe4B9wFeBO+Ys+17gOFWZf4ieA4OZeTgz989egEeBmcx8qIXHIEnLUuzL5RYTEZdm5u1rfYY2RcQLM/PODu//ucDBzLy/qxkGzYwHq+t86xn6yngoi1mSRlnpuzIkac2xmCWpMBazJBWmkdcxj4+P5+TkZBOrWpGZmRnGxsY6u/+5M+zevfvAck/+IkmzGinmyclJdu3a1cSqVmR6epqpqanO7n/uDBFxT6fDSBpq7sqQpMIsusUcEZcCx+Z77V/veVYnJiaYnp4GYM++fs4n1KyJ9fC+Wz7Z+v32etbGdY9lIEmr0cjrmLdu3ZqzuzJ6P3qpLds3n+CGPd2e9uOmK8Z6d2XsHuVz2koaLHdlSFJhLGZJKozFLEmFsZglqTAWsyQVxmKWpMJYzJJUGItZkgpjMUtSYSxmSSqMxSxJhbGYJakwFrMkFcZilqTCWMySVBiLWZIKYzFLUmEsZkkqjMUsSYWxmCWpMBazJBXGYpakwljMklQYi1mSCmMxS1JhLGZJKozFLEmFsZglqTAWsyQVxmKWpMJYzJJUGItZkgpjMUtSYSxmSSqMxSxJhbGYJakwFrMkFcZilqTCWMySVBiLWZIKE5m59EIRl2TmHXOu2wZsq7+9ELir+fH6Ng4c6PD+586wKTPP6XIYScOrr2IuXUTsysyta30GSaPBXRmSVBiLWZIKMyrFvKPrAShjBkkjYCT2MUvSKBmVLWZJGhkWsyQVZiSKOSJe2PH9PzciJrqcQdLocB+zJBVmJLaYJWmUWMySVBiLWZIKYzFLUmEsZkkqzP8HJwLFh6S0eZcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tau1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015586</td>\n",
       "      <td>-0.005970</td>\n",
       "      <td>-0.017265</td>\n",
       "      <td>0.027183</td>\n",
       "      <td>-0.015485</td>\n",
       "      <td>-0.015924</td>\n",
       "      <td>-0.015807</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>0.015350</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.275761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau2</th>\n",
       "      <td>0.015586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>-0.004769</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>-0.005963</td>\n",
       "      <td>-0.001742</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>-0.011764</td>\n",
       "      <td>0.290975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau3</th>\n",
       "      <td>-0.005970</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>-0.008780</td>\n",
       "      <td>-0.017531</td>\n",
       "      <td>-0.011605</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>-0.011497</td>\n",
       "      <td>0.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau4</th>\n",
       "      <td>-0.017265</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003173</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>-0.011211</td>\n",
       "      <td>-0.004149</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>0.278576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <td>0.027183</td>\n",
       "      <td>-0.004769</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>-0.003173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.573157</td>\n",
       "      <td>-0.584554</td>\n",
       "      <td>-0.579239</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>-0.015451</td>\n",
       "      <td>0.010278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2</th>\n",
       "      <td>-0.015485</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>-0.573157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>-0.006844</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>-0.018032</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.006255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3</th>\n",
       "      <td>-0.015924</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>-0.008780</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>-0.584554</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012953</td>\n",
       "      <td>-0.003219</td>\n",
       "      <td>-0.011575</td>\n",
       "      <td>-0.005897</td>\n",
       "      <td>-0.010485</td>\n",
       "      <td>-0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4</th>\n",
       "      <td>-0.015807</td>\n",
       "      <td>-0.005963</td>\n",
       "      <td>-0.017531</td>\n",
       "      <td>-0.011211</td>\n",
       "      <td>-0.579239</td>\n",
       "      <td>-0.006844</td>\n",
       "      <td>0.012953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013636</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>-0.003515</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>-0.020786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1</th>\n",
       "      <td>0.010521</td>\n",
       "      <td>-0.001742</td>\n",
       "      <td>-0.011605</td>\n",
       "      <td>-0.004149</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>-0.003219</td>\n",
       "      <td>-0.013636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>0.282774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g2</th>\n",
       "      <td>0.015350</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>-0.018032</td>\n",
       "      <td>-0.011575</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012809</td>\n",
       "      <td>-0.014909</td>\n",
       "      <td>0.293601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g3</th>\n",
       "      <td>-0.001279</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>-0.005897</td>\n",
       "      <td>-0.003515</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>-0.012809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.308235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g4</th>\n",
       "      <td>0.005494</td>\n",
       "      <td>-0.011764</td>\n",
       "      <td>-0.011497</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>-0.015451</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>-0.010485</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>-0.014909</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab</th>\n",
       "      <td>0.275761</td>\n",
       "      <td>0.290975</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.278576</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>-0.003321</td>\n",
       "      <td>-0.020786</td>\n",
       "      <td>0.282774</td>\n",
       "      <td>0.293601</td>\n",
       "      <td>0.308235</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "tau1  1.000000  0.015586 -0.005970 -0.017265  0.027183 -0.015485 -0.015924   \n",
       "tau2  0.015586  1.000000  0.014273 -0.001965 -0.004769  0.006573  0.007673   \n",
       "tau3 -0.005970  0.014273  1.000000  0.004354  0.016953 -0.003134 -0.008780   \n",
       "tau4 -0.017265 -0.001965  0.004354  1.000000 -0.003173  0.010553  0.006169   \n",
       "p1    0.027183 -0.004769  0.016953 -0.003173  1.000000 -0.573157 -0.584554   \n",
       "p2   -0.015485  0.006573 -0.003134  0.010553 -0.573157  1.000000  0.002388   \n",
       "p3   -0.015924  0.007673 -0.008780  0.006169 -0.584554  0.002388  1.000000   \n",
       "p4   -0.015807 -0.005963 -0.017531 -0.011211 -0.579239 -0.006844  0.012953   \n",
       "g1    0.010521 -0.001742 -0.011605 -0.004149  0.000721  0.015603 -0.003219   \n",
       "g2    0.015350  0.015383  0.007671  0.008431  0.015405 -0.018032 -0.011575   \n",
       "g3   -0.001279  0.016508  0.014702  0.003260  0.001069  0.007555 -0.005897   \n",
       "g4    0.005494 -0.011764 -0.011497 -0.000491 -0.015451  0.019817 -0.010485   \n",
       "stab  0.275761  0.290975  0.280700  0.278576  0.010278  0.006255 -0.003321   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab  \n",
       "tau1 -0.015807  0.010521  0.015350 -0.001279  0.005494  0.275761  \n",
       "tau2 -0.005963 -0.001742  0.015383  0.016508 -0.011764  0.290975  \n",
       "tau3 -0.017531 -0.011605  0.007671  0.014702 -0.011497  0.280700  \n",
       "tau4 -0.011211 -0.004149  0.008431  0.003260 -0.000491  0.278576  \n",
       "p1   -0.579239  0.000721  0.015405  0.001069 -0.015451  0.010278  \n",
       "p2   -0.006844  0.015603 -0.018032  0.007555  0.019817  0.006255  \n",
       "p3    0.012953 -0.003219 -0.011575 -0.005897 -0.010485 -0.003321  \n",
       "p4    1.000000 -0.013636  0.002850 -0.003515  0.017505 -0.020786  \n",
       "g1   -0.013636  1.000000  0.007559 -0.005836  0.012431  0.282774  \n",
       "g2    0.002850  0.007559  1.000000 -0.012809 -0.014909  0.293601  \n",
       "g3   -0.003515 -0.005836 -0.012809  1.000000  0.006900  0.308235  \n",
       "g4    0.017505  0.012431 -0.014909  0.006900  1.000000  0.279214  \n",
       "stab -0.020786  0.282774  0.293601  0.308235  0.279214  1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(data.corr(), vmin=-1, vmax=1, interpolation='none')\n",
    "fig.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping one of the target variables - stab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('stab', inplace= True, axis= 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the target or dependent(y) variable from the independent variables(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns = 'stabf')\n",
    "y = data['stabf']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split-out into 80-20 train-test splits with random state of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming x_train and x_test using standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       " 0     0.367327 -0.986042  0.650447  1.547527 -0.291490  0.061535  1.293862   \n",
       " 1    -0.064659  0.089437  1.035079 -1.641494  0.619865 -0.067235 -1.502925   \n",
       " 2    -1.467850  1.298418 -0.502536  1.166046 -0.180521  0.490603  0.682560   \n",
       " 3     0.820081  0.529920  1.299657 -1.141975 -0.812854 -0.763632  1.521579   \n",
       " 4     0.665424 -1.425627  0.312300  0.919137 -1.614296  0.760315  1.422019   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 7995  1.551314  0.007408 -1.177640  1.016898 -0.397177  0.759820 -0.636951   \n",
       " 7996  1.015925 -0.223483 -1.489381 -1.479078  0.451468 -0.731994  0.990355   \n",
       " 7997  0.657609 -0.722756 -1.405888 -0.274301 -0.012584  1.438694 -0.364266   \n",
       " 7998 -0.059316 -1.260532 -1.010471 -0.877808 -0.779769  0.828824  0.516923   \n",
       " 7999 -1.473214  0.638438  0.250122 -0.996484  1.950944 -1.163800 -0.732842   \n",
       " \n",
       "             p4        g1        g2        g3        g4  \n",
       " 0    -0.845074  0.160918  0.339859  0.585568  0.492239  \n",
       " 1     0.486613 -0.293143 -1.558488  1.429649 -1.443521  \n",
       " 2    -0.855302  1.399350  1.451534 -1.045743  0.492489  \n",
       " 3     0.658780 -0.958319  1.361958  1.604140  0.275303  \n",
       " 4     0.639243  1.676895  0.695660  1.137504 -1.312575  \n",
       " ...        ...       ...       ...       ...       ...  \n",
       " 7995  0.572703 -1.209413  0.313976 -1.625728 -0.637401  \n",
       " 7996 -1.048148 -1.094647 -0.755209  0.734821 -0.304433  \n",
       " 7997 -1.046683  1.253539  0.293100 -1.550587  0.810344  \n",
       " 7998  0.018984 -0.182448 -0.388255 -0.726781  1.667916  \n",
       " 7999 -1.513302  1.230438 -1.174110  1.179282  0.783627  \n",
       " \n",
       " [8000 rows x 12 columns],\n",
       "           tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       " 0     0.593951 -0.412733  1.503924  1.116943  0.403423 -1.492971 -0.785033   \n",
       " 1     0.202190  0.374416 -0.188800 -0.522268 -0.225967 -1.058483  0.420047   \n",
       " 2    -1.079044 -0.313745 -0.884634  0.017080 -0.943122  0.112653  0.801335   \n",
       " 3    -0.083120 -1.107327  0.372805 -1.708152  0.753990 -1.637972  0.403805   \n",
       " 4     0.873921  1.438466  0.086662  1.715037 -0.153880 -0.007015 -0.197053   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 1995  1.119679 -0.675220 -1.382912  1.287865  0.249565 -0.803325  0.734497   \n",
       " 1996 -1.077913 -0.808691  1.033449  0.337636 -0.166587  0.340913  0.988085   \n",
       " 1997  0.947825 -1.663727 -1.653920  0.532665 -1.518329  1.590144  0.091613   \n",
       " 1998 -1.120235  0.193979 -0.237805  0.421570 -1.162671  0.738702  0.027367   \n",
       " 1999 -1.377640  1.511867  0.282651  1.510837  0.648241 -1.486786 -0.781586   \n",
       " \n",
       "             p4        g1        g2        g3        g4  \n",
       " 0     1.566781 -0.901007  1.167203 -1.507330  1.084726  \n",
       " 1     1.028627 -1.625721 -0.395660  1.414651  1.226011  \n",
       " 2     0.733004  1.457108 -1.438495  0.651821 -1.682168  \n",
       " 3    -0.088036  0.083322 -1.672322 -0.357714  1.055865  \n",
       " 4     0.472315  0.136549 -1.469731  0.956396 -0.819727  \n",
       " ...        ...       ...       ...       ...       ...  \n",
       " 1995 -0.369263  0.485786 -0.115528 -1.264683 -1.283117  \n",
       " 1996 -1.035753  0.952386  0.892766 -1.062502 -1.094114  \n",
       " 1997  0.974455 -1.233963  0.126391  0.573445  1.319350  \n",
       " 1998  1.265833  1.524336  0.794087 -1.362323 -0.801971  \n",
       " 1999  1.130007  0.493337 -0.917497  0.002950  1.189023  \n",
       " \n",
       " [2000 rows x 12 columns])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "                    \n",
    "rescaled_x_train = scaler.fit_transform(x_train)\n",
    "rescaled_x_train = pd.DataFrame(rescaled_x_train, columns= x_train.columns)\n",
    "\n",
    "rescaled_x_test = scaler.transform(x_test)\n",
    "rescaled_x_test = pd.DataFrame(rescaled_x_test, columns= x_test.columns)\n",
    "\n",
    "#the scaled features\n",
    "rescaled_x_train, rescaled_x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using scikit learn to train random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91143756 0.91136454 0.91564855 0.90214725 0.91555674]\n",
      "Accuracy: 0.929\n",
      "[[ 625   87]\n",
      " [  55 1233]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.92      0.88      0.90       712\n",
      "    unstable       0.93      0.96      0.95      1288\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.92      0.92      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(random_state=1)\n",
    "model_rf.fit(rescaled_x_train, y_train)\n",
    "\n",
    "#predict on test set\n",
    "rf_predictions = model_rf.predict(rescaled_x_test)\n",
    "rf_predictions\n",
    "\n",
    "#cross validation score\n",
    "scores = cross_val_score(model_rf, rescaled_x_train, y_train, cv=5,\n",
    "                        scoring='f1_macro')\n",
    "print(scores)\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print('Accuracy: {}'.format(round(accuracy, 4)))\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, rf_predictions)\n",
    "print(cm)\n",
    "\n",
    "#classification report\n",
    "report = classification_report(y_test, rf_predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Result shows that the accuracy on the test set using RandomForest classifier is 0.9295'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Result shows that the accuracy on the test set using RandomForest classifier is 0.9295\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using scikit learn to train extra trees classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91055206 0.91915686 0.91272727 0.90320952 0.91168746]\n",
      "Accuracy: 0.9235\n",
      "[[ 594  118]\n",
      " [  35 1253]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.94      0.83      0.89       712\n",
      "    unstable       0.91      0.97      0.94      1288\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.93      0.90      0.91      2000\n",
      "weighted avg       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model_et = ExtraTreesClassifier()\n",
    "model_et.fit(rescaled_x_train, y_train)\n",
    "et_predictions = model_et.predict(rescaled_x_test)\n",
    "et_predictions\n",
    "\n",
    "#cross validation score\n",
    "scores = cross_val_score(model_et, rescaled_x_train, y_train, cv=5,\n",
    "                        scoring='f1_macro')\n",
    "print(scores)\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy = accuracy_score(y_test, et_predictions)\n",
    "print('Accuracy: {}'.format(round(accuracy, 4)))\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, et_predictions)\n",
    "print(cm)\n",
    "\n",
    "#classification report\n",
    "report = classification_report(y_test, et_predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "hyperparameter_grid = {'n_estimators': n_estimators,'min_samples_leaf': min_samples_leaf,'min_samples_split': min_samples_split,'max_features': max_features}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92425\n",
      "ExtraTreesClassifier(max_features=None, min_samples_leaf=8, n_estimators=1000)\n",
      "{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "r_search = RandomizedSearchCV(model_et, hyperparameter_grid, random_state=1)\n",
    "search = r_search.fit(rescaled_x_train, y_train)\n",
    "print(search.best_score_)\n",
    "print(search.best_estimator_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Result shows the best hyperparameters from the RandomizedSearchCV is as follows:n_estimators=1000, min_samples_split=2, min_samples_leaf=8, max_features=None   '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Result shows the best hyperparameters from the RandomizedSearchCV is as follows:n_estimators=1000, min_samples_split=2, min_samples_leaf=8, max_features=None   \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with this parameters to improve the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "et_param = ExtraTreesClassifier(n_estimators=1000, min_samples_split=2, \n",
    "                                 min_samples_leaf=8, max_features=None, random_state=1)\n",
    "et_param.fit(rescaled_x_train, y_train)\n",
    "et_param_pred = et_param.predict(rescaled_x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90914572 0.92150801 0.91752855 0.91018859 0.92385757]\n",
      "Accuracy: 0.927\n",
      "[[ 619   93]\n",
      " [  53 1235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.92      0.87      0.89       712\n",
      "    unstable       0.93      0.96      0.94      1288\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.91      0.92      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cross validation score\n",
    "scores = cross_val_score(et_param, rescaled_x_train, y_train, cv=5,\n",
    "                        scoring='f1_macro')\n",
    "print(scores)\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy = accuracy_score(y_test, et_param_pred)\n",
    "print('Accuracy: {}'.format(round(accuracy, 4)))\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, et_param_pred)\n",
    "print(cm)\n",
    "\n",
    "#classification report\n",
    "report = classification_report(y_test, et_param_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From the results we can say that the accuracy of the new optimal model(0.927) is lower than the initial ExtraTrees classifier model(0.9235) without hyperparameter tuning '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"From the results we can say that the accuracy of the new optimal model(0.927) is lower than the initial ExtraTrees classifier model(0.9235) without hyperparameter tuning \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the feature importance using the Extra Trees classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13793336 0.14019889 0.13425523 0.13452351 0.0037668  0.00548612\n",
      " 0.00537243 0.0051141  0.10251288 0.10868147 0.11238751 0.1097677 ]\n"
     ]
    }
   ],
   "source": [
    "feature_importances = r_search.best_estimator_.feature_importances_\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.14019888830166377, 'tau2'),\n",
       " (0.1379333628328318, 'tau1'),\n",
       " (0.13452351402411436, 'tau4'),\n",
       " (0.13425522972508763, 'tau3'),\n",
       " (0.11238751030473944, 'g3'),\n",
       " (0.10976769867211555, 'g4'),\n",
       " (0.10868146672868398, 'g2'),\n",
       " (0.10251288016863494, 'g1'),\n",
       " (0.005486120071676659, 'p2'),\n",
       " (0.005372433038866207, 'p3'),\n",
       " (0.005114100631849415, 'p4'),\n",
       " (0.003766795499736256, 'p1')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(feature_importances, x),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From the results above we can see that tau2 and p1 are the most and least importance features respectively'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"From the results above we can see that tau2 and p1 are the most and least importance features respectively\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit xgboost model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(max_depth=3,subsample=1, objective='binary:logistic', n_estimators=100, learning_rate = 0.1, random_state=1)\n",
    "model_xgb.fit(rescaled_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89416221 0.91816775 0.91843641 0.9083106  0.92672083]\n",
      "Accuracy: 0.9195\n",
      "[[ 603  109]\n",
      " [  52 1236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.92      0.85      0.88       712\n",
      "    unstable       0.92      0.96      0.94      1288\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.92      0.90      0.91      2000\n",
      "weighted avg       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "xgb_predictions = model_xgb.predict(rescaled_x_test)\n",
    "xgb_predictions\n",
    "\n",
    "#cross validation score\n",
    "scores = cross_val_score(model_xgb, rescaled_x_train, y_train, cv=5,\n",
    "                        scoring='f1_macro')\n",
    "print(scores)\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy = accuracy_score(y_test, xgb_predictions)\n",
    "print('Accuracy: {}'.format(round(accuracy, 4)))\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, xgb_predictions)\n",
    "print(cm)\n",
    "\n",
    "#calssification report\n",
    "report = classification_report(y_test, xgb_predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From the result it shows that the accuracy for the xgboost classifier model is 0.9195'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"From the result it shows that the accuracy for the xgboost classifier model is 0.9195\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Light Gragient Boosting Model (LGBM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "model_lgb = lgb.LGBMClassifier(random_state=1)\n",
    "model_lgb.fit(rescaled_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92724105 0.94904006 0.92404514 0.9281486  0.93680968]\n",
      "Accuracy: 0.9375\n",
      "[[ 635   77]\n",
      " [  48 1240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.93      0.89      0.91       712\n",
      "    unstable       0.94      0.96      0.95      1288\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.94      0.93      0.93      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "lgb_predictions = model_lgb.predict(rescaled_x_test)\n",
    "lgb_predictions\n",
    "\n",
    "#cross validation score\n",
    "scores = cross_val_score(model_lgb, rescaled_x_train, y_train, cv=5,\n",
    "                        scoring='f1_macro')\n",
    "print(scores)\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy = accuracy_score(y_test, lgb_predictions)\n",
    "print('Accuracy: {}'.format(round(accuracy, 4)))\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, lgb_predictions)\n",
    "print(cm)\n",
    "\n",
    "#calssification report\n",
    "report = classification_report(y_test, lgb_predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Result shows that the accuracy on the test set using LGBM classifier is 0.9375'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Result shows that the accuracy on the test set using LGBM classifier is 0.9375\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tried training some additional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_dt = DecisionTreeClassifier(random_state=1)\n",
    "model_dt.fit(rescaled_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82469536 0.82319881 0.81088821 0.82887476 0.83538845]\n",
      "Accuracy: 0.9375\n",
      "[[ 635   77]\n",
      " [  48 1240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.93      0.89      0.91       712\n",
      "    unstable       0.94      0.96      0.95      1288\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.94      0.93      0.93      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "dt_predictions = model_lgb.predict(rescaled_x_test)\n",
    "dt_predictions\n",
    "\n",
    "#cross validation score\n",
    "scores = cross_val_score(model_dt, rescaled_x_train, y_train, cv=5,\n",
    "                        scoring='f1_macro')\n",
    "print(scores)\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print('Accuracy: {}'.format(round(accuracy, 4)))\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, dt_predictions)\n",
    "print(cm)\n",
    "\n",
    "#calssification report\n",
    "report = classification_report(y_test, dt_predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8049015  0.80345987 0.80785034 0.79645688 0.7835111 ]\n",
      "Accuracy: 0.804\n",
      "[[ 494  218]\n",
      " [ 174 1114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.74      0.69      0.72       712\n",
      "    unstable       0.84      0.86      0.85      1288\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.79      0.78      0.78      2000\n",
      "weighted avg       0.80      0.80      0.80      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lr = LogisticRegression(max_iter=100, random_state=1)\n",
    "model_lr.fit(rescaled_x_train, y_train)\n",
    "lr_predictions = model_lr.predict(rescaled_x_test)\n",
    "\n",
    "#cross validation score\n",
    "scores = cross_val_score(model_lr, rescaled_x_train, y_train, cv=5,\n",
    "                        scoring='f1_macro')\n",
    "print(scores)\n",
    "\n",
    "#calculate accuracy\n",
    "accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print('Accuracy: {}'.format(round(accuracy, 4)))\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, lr_predictions)\n",
    "print(cm)\n",
    "\n",
    "#calssification report\n",
    "report = classification_report(y_test, lr_predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
